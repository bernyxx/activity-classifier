{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from os import listdir\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read every dataset in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir('datasets')\n",
    "\n",
    "datasets = []\n",
    "datasets_train = []\n",
    "datasets_test = []\n",
    "\n",
    "def add_activity(name, df):\n",
    "    if 'still' in name:\n",
    "        df['activity'] = 'still'\n",
    "    elif 'walking' in name:\n",
    "        df['activity'] = 'walking'\n",
    "    else:\n",
    "        df['activity'] = 'running'\n",
    "    return df\n",
    "\n",
    "def split_data(df):\n",
    "    num_rows = df.shape[0]\n",
    "    num_test = math.floor(num_rows / 3)\n",
    "    num_train = num_rows - num_test\n",
    "\n",
    "    df_train = df.iloc[:num_train, :]\n",
    "    df_test = df.iloc[num_train:, :]\n",
    "\n",
    "    datasets_train.append(df_train)\n",
    "    datasets_test.append(df_test)\n",
    "\n",
    "    print(df_train.shape)\n",
    "    print(df_test.shape)\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    df = add_activity(file, pd.read_csv(f'datasets/{file}'))\n",
    "    datasets.append(df)\n",
    "    print(\"Dimensione dataset {} \".format(file), df.shape)\n",
    "\n",
    "for df in datasets:\n",
    "    split_data(df)\n",
    "\n",
    "df_train = pd.concat(datasets_train, ignore_index=True)\n",
    "df_test = pd.concat(datasets_test, ignore_index=True)\n",
    "\n",
    "print(\"Dimensione merged dataset train \", df_train.shape)\n",
    "print(\"Dimensione merged dataset test \", df_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizzazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xa</th>\n",
       "      <th>ya</th>\n",
       "      <th>za</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.559771</td>\n",
       "      <td>0.579491</td>\n",
       "      <td>0.620094</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577511</td>\n",
       "      <td>0.452969</td>\n",
       "      <td>0.797305</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.278930</td>\n",
       "      <td>0.677610</td>\n",
       "      <td>0.724956</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200055</td>\n",
       "      <td>0.753965</td>\n",
       "      <td>0.755126</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697052</td>\n",
       "      <td>0.390631</td>\n",
       "      <td>0.651142</td>\n",
       "      <td>running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.613537</td>\n",
       "      <td>0.829583</td>\n",
       "      <td>0.548916</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.614083</td>\n",
       "      <td>0.847658</td>\n",
       "      <td>0.512595</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.627456</td>\n",
       "      <td>0.808558</td>\n",
       "      <td>0.456649</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.603166</td>\n",
       "      <td>0.806345</td>\n",
       "      <td>0.453134</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.620906</td>\n",
       "      <td>0.797123</td>\n",
       "      <td>0.383421</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           xa        ya        za activity\n",
       "0    0.559771  0.579491  0.620094  running\n",
       "1    0.577511  0.452969  0.797305  running\n",
       "2    0.278930  0.677610  0.724956  running\n",
       "3    0.200055  0.753965  0.755126  running\n",
       "4    0.697052  0.390631  0.651142  running\n",
       "..        ...       ...       ...      ...\n",
       "226  0.613537  0.829583  0.548916  walking\n",
       "227  0.614083  0.847658  0.512595  walking\n",
       "228  0.627456  0.808558  0.456649  walking\n",
       "229  0.603166  0.806345  0.453134  walking\n",
       "230  0.620906  0.797123  0.383421  walking\n",
       "\n",
       "[231 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "num_columns = df_train.shape[1]\n",
    "\n",
    "normalizer.fit(df_train.iloc[:, 0 : num_columns-1])\n",
    "\n",
    "def normalize_df(df):\n",
    "    \n",
    "    norm_df = df.copy()\n",
    "    norm_column = normalizer.transform(df.iloc[:, 0 : num_columns-1])\n",
    "    norm_df.iloc[:, 0 : num_columns-1] = norm_column\n",
    "\n",
    "    return norm_df\n",
    "\n",
    "norm_train_df = normalize_df(df_train)\n",
    "norm_test_df = normalize_df(df_test)\n",
    "\n",
    "\n",
    "# fig, ((ax1, ax2),( ax3, ax4), (ax5, ax6)) = plt.subplots(3,2)\n",
    "# ax1.plot(np.arange(0, len(df_train.xa)), df_train.xa)\n",
    "# ax3.plot(np.arange(0, len(df_train.ya)), df_train.ya)\n",
    "# ax5.plot(np.arange(0, len(df_train.za)), df_train.za)\n",
    "\n",
    "# ax2.plot(np.arange(0, len(norm_train_df.xa)), norm_train_df.xa)\n",
    "# ax4.plot(np.arange(0, len(norm_train_df.ya)), norm_train_df.ya)\n",
    "# ax6.plot(np.arange(0, len(norm_train_df.za)), norm_train_df.za)\n",
    "\n",
    "# fig, ((ax1, ax2),( ax3, ax4), (ax5, ax6)) = plt.subplots(3,2)\n",
    "# ax1.plot(np.arange(0, len(df_test.xa)), df_test.xa)\n",
    "# ax3.plot(np.arange(0, len(df_test.ya)), df_test.ya)\n",
    "# ax5.plot(np.arange(0, len(df_test.za)), df_test.za)\n",
    "\n",
    "# ax2.plot(np.arange(0, len(norm_test_df.xa)), norm_test_df.xa)\n",
    "# ax4.plot(np.arange(0, len(norm_test_df.ya)), norm_test_df.ya)\n",
    "# ax6.plot(np.arange(0, len(norm_test_df.za)), norm_test_df.za)\n",
    "\n",
    "norm_train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "num_cols = norm_train_df.shape[1]\n",
    "\n",
    "X = df.iloc[:, :num_cols - 1]\n",
    "y = df.iloc[:, num_cols - 1:]\n",
    "\n",
    "\n",
    "def reshape_data(df, time_steps, step):\n",
    "    Xs = []\n",
    "    ys = []\n",
    "\n",
    "    X = df.iloc[:, :num_cols - 1]\n",
    "    y = df.iloc[:, num_cols - 1:]\n",
    "\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        values = X.iloc[i : (i+time_steps)].values\n",
    "        labels = y.iloc[i : i + time_steps]\n",
    "        Xs.append(values)\n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    \n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoder per la y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_y(df):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    encoded_y = encoder.fit_transform(df.activity.to_numpy().reshape(-1, 1))\n",
    "\n",
    "    df[encoder.categories_[0]] = encoded_y\n",
    "    encoded_df = df.drop('activity', axis=1)\n",
    "    return encoded_df\n",
    "\n",
    "encoded_train_df = encode_y(norm_train_df)\n",
    "encoded_test_df = encode_y(norm_test_df)\n",
    "\n",
    "print(encoded_train_df)\n",
    "print(encoded_test_df)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = encoded_train_df.shape[1]\n",
    "num_cols_y = 3\n",
    "num_cols_x = num_cols - num_cols_y\n",
    "\n",
    "X_train = encoded_train_df.iloc[:, :num_cols_x]\n",
    "Y_train = encoded_train_df.iloc[:, num_cols_x:]\n",
    "X_test = encoded_test_df.iloc[:, :num_cols_x]\n",
    "Y_test = encoded_test_df.iloc[:, num_cols_x:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(11,), activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modello - ottimizzatore e funzione di perdita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping per evitare overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    batch_size=512,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2e6baf65b4912df534866df4a24f335b0ddd2a79686966292e6a89b41752c6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
